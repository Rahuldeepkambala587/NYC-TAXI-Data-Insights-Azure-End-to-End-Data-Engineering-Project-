# ğŸš– NYC-TAXI-Data-Insights-Azure-End-to-End-Data-Engineering-Project

The NYC Taxi Trip Insights Pipeline is designed to process large-scale taxi trip data efficiently using Azure services. The goal is to demonstrate expertise in data ingestion, transformation, and storage while optimizing performance and cost.

---

## ğŸ¯ 1ï¸âƒ£ Business Goal
The goal of this project is to leverage NYC taxi trip data to enhance operational efficiency, optimize pricing strategies, and improve overall service planning.  

### Key Objectives:
- ğŸ“ˆ **Understand demand patterns** â€“ Identify peak hours, high-demand locations, and seasonal trends to help taxi operators optimize fleet distribution.  
- ğŸ’° **Optimize fare structures** â€“ Analyze trip distances, durations, and pricing strategies to ensure competitive and profitable fare models.  
- âš¡ **Build a scalable data pipeline** â€“ Process real-time and batch data efficiently for future forecasting and analytics.  
- ğŸ“Š **Provide insights for stakeholders** â€“ Deliver clean, structured, and aggregated data for easy consumption in Power BI to support business decision-making.  

---

## ğŸ—ï¸ 2ï¸âƒ£ Architecture & Tech Stack

### Architecture:
<img width="823" height="484" alt="image" src="https://github.com/user-attachments/assets/74a01106-4633-4a9b-9f80-e92fb9170016" />

### Tools & Services Used:
- ğŸ”„ **Data Ingestion**: Azure Data Factory (ADF) â€“ REST API ingestion  
- ğŸ—„ï¸ **Storage**: Azure Data Lake Storage (ADLS) â€“ Bronze, Silver, Gold layers  
- ğŸ”¥ **Processing**: Azure Databricks (PySpark transformations)  
- ğŸ—ƒï¸ **Storage Format**: Delta Lake â€“ for data versioning & optimization  
- ğŸ“ˆ **Visualization**: Power BI  

### Architecture Flow:
1. **Ingestion Layer (Bronze)** â€“ Data is pulled from the taxi API and stored in raw format in ADLS.  
2. **Processing Layer (Silver)** â€“ Databricks reads Bronze data, applies transformations, and saves it in optimized Parquet format.  
3. **Serving Layer (Gold)** â€“ Data is further aggregated and stored in Delta Tables for analytics and reporting.  
4. **Consumption** â€“ Data is visualized in Power BI.  

---

## ğŸ”„ 3ï¸âƒ£ Step-by-Step Implementation

### Step 1: Data Ingestion (Bronze Layer)
- ğŸŒ Used Azure Data Factory to fetch data from the taxi API.  
- ğŸ”„ Implemented ForEach Activity to load data in parallel.  
- ğŸ—„ï¸ Stored raw JSON/CSV files in ADLS.  

### Step 2: Transformation (Silver Layer)
- ğŸ”¥ Used Databricks with Service Principal to access ADLS.  
- ğŸ§¹ Cleaned missing values, standardized timestamps, and converted data to Parquet format.  
- ğŸ“‚ Applied partitioning for faster querying.  

### Step 3: Data Aggregation & Storage (Gold Layer)
- ğŸ—ƒï¸ Moved data from Silver to Gold using Delta Lake.  
- ğŸ”„ Created Delta Tables to enable data versioning and schema evolution.  

### Step 4: Data Visualization
- ğŸ“ˆ Connected Power BI to ADLS for building dashboards.  
- ğŸ” Analyzed fare trends, trip density, and peak demand times.  

---

## ğŸ›‘ 4ï¸âƒ£ Challenges Faced & Solutions

| âš ï¸ **Challenges** | âœ… **Solutions Implemented** |
|--------------------|----------------------------|
| High API response time | Used parallel ingestion in ADF |
| Data inconsistencies | Applied schema enforcement in Databricks |
| Query performance issues | Used Delta Lake with partitioning |
| High storage cost | Compressed data using Parquet format |
| Managing Databricks cluster costs | Set auto-termination after inactivity |
| Schema evolution issues | Used Delta Lake for handling changes |
| Data versioning & tracking changes | Implemented Delta Lake time travel |

---

## ğŸ‘¨â€ğŸ’» 5ï¸âƒ£ Role & Contributions
- ğŸ—ï¸ Designed & Implemented an end-to-end data pipeline using Azure services.  
- ğŸ”¥ Optimized Data Processing by applying PySpark transformations in Databricks.  
- ğŸ—ƒï¸ Managed Data Consistency with Delta Lake for schema enforcement and time travel.  
- âš¡ Improved Query Performance by partitioning data and using optimized storage formats.  
- ğŸ’° Reduced Costs by enabling auto-termination of Databricks clusters and optimizing storage.  
- ğŸ“Š Built Power BI Dashboards for data visualization and analytics.  

---

## ğŸš€ 6ï¸âƒ£ Business Impact & Outcomes
- âœ… **Optimized trip analysis** â€“ Identified peak hours & routes.  
- âœ… **Improved performance** â€“ Queries run 5x faster with Delta Lake.  
- âœ… **Cost-efficient storage** â€“ Reduced costs by using optimized formats.  
- âœ… **Scalable solution** â€“ Handles real-time and batch processing.  
